{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7294ae7d-0ccc-4ced-9471-8d9e9466c50d",
    "_uuid": "d2b8be80-b5d0-49cc-bd29-db029770264b",
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:27.438177Z",
     "iopub.status.busy": "2025-03-29T15:17:27.437688Z",
     "iopub.status.idle": "2025-03-29T15:17:27.462538Z",
     "shell.execute_reply": "2025-03-29T15:17:27.461576Z",
     "shell.execute_reply.started": "2025-03-29T15:17:27.438120Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/arcade_nl2code/annotated_dataset/dataset/existing_tasks/artifacts'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:27.464297Z",
     "iopub.status.busy": "2025-03-29T15:17:27.463933Z",
     "iopub.status.idle": "2025-03-29T15:17:27.474867Z",
     "shell.execute_reply": "2025-03-29T15:17:27.473893Z",
     "shell.execute_reply.started": "2025-03-29T15:17:27.464263Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_USERNAME'] = 'KAGGLE_USERNAME'\n",
    "os.environ['KAGGLE_KEY'] = 'KAGGLE_KEY'\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate with Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ARCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:27.477095Z",
     "iopub.status.busy": "2025-03-29T15:17:27.476786Z",
     "iopub.status.idle": "2025-03-29T15:17:28.820424Z",
     "shell.execute_reply": "2025-03-29T15:17:28.819343Z",
     "shell.execute_reply.started": "2025-03-29T15:17:27.477066Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/google-research/arcade-nl2code.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:28.822970Z",
     "iopub.status.busy": "2025-03-29T15:17:28.822579Z",
     "iopub.status.idle": "2025-03-29T15:17:28.833302Z",
     "shell.execute_reply": "2025-03-29T15:17:28.832313Z",
     "shell.execute_reply.started": "2025-03-29T15:17:28.822930Z"
    }
   },
   "outputs": [],
   "source": [
    "# createa a package out of arcade and install it\n",
    "setup_content = \"\"\"\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name='arcade_nl2code',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    install_requires=[\n",
    "        'tensorflow',  # Add other dependencies here\n",
    "    ],\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "with open('/kaggle/working/arcade-nl2code/setup.py', 'w') as file:\n",
    "    file.write(setup_content)\n",
    "\n",
    "def create_init_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for dir_name in dirs:\n",
    "            init_file_path = os.path.join(root, dir_name, '__init__.py')\n",
    "            if not os.path.exists(init_file_path):\n",
    "                with open(init_file_path, 'w') as f:\n",
    "                    f.write(\"# This file makes the directory a Python package\\n\")\n",
    "                print(f\"Created: {init_file_path}\")\n",
    "\n",
    "directory = '//kaggle/working/arcade-nl2code'\n",
    "create_init_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:28.834712Z",
     "iopub.status.busy": "2025-03-29T15:17:28.834370Z",
     "iopub.status.idle": "2025-03-29T15:17:38.680401Z",
     "shell.execute_reply": "2025-03-29T15:17:38.679380Z",
     "shell.execute_reply.started": "2025-03-29T15:17:28.834677Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/working/arcade-nl2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:38.681876Z",
     "iopub.status.busy": "2025-03-29T15:17:38.681599Z",
     "iopub.status.idle": "2025-03-29T15:17:38.687468Z",
     "shell.execute_reply": "2025-03-29T15:17:38.686447Z",
     "shell.execute_reply.started": "2025-03-29T15:17:38.681842Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# add the package to python path\n",
    "sys.path.append('/kaggle/working/arcade-nl2code')\n",
    "sys.path.append('/kaggle/working/arcade-nl2code/arcade_nl2code')\n",
    "sys.path.append('/kaggle/working/arcade-nl2code/arcade_nl2code/annotated_dataset')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:38.688655Z",
     "iopub.status.busy": "2025-03-29T15:17:38.688364Z",
     "iopub.status.idle": "2025-03-29T15:17:38.703935Z",
     "shell.execute_reply": "2025-03-29T15:17:38.703133Z",
     "shell.execute_reply.started": "2025-03-29T15:17:38.688632Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a requirements file for possible versions \n",
    "reqs_2022 = \"\"\"\n",
    "tensorflow-cpu==2.10.0\n",
    "absl-py==1.3.0\n",
    "pandas==1.5.2\n",
    "dacite==1.7.0\n",
    "nbformat==5.7.0\n",
    "dill==0.3.6\n",
    "sacrebleu==2.3.1\n",
    "astor==0.8.1\n",
    "folium==0.12.1\n",
    "seaborn==0.12.2\n",
    "vega==3.5.0\n",
    "bokeh==2.4.3\n",
    "plotly==5.10.0\n",
    "matplotlib==3.6.2\n",
    "chart_studio==1.1.0\n",
    "\"\"\"\n",
    "\n",
    "with open('/kaggle/working/arcade-nl2code/requirements_2022.txt', 'w') as file:\n",
    "    file.write(reqs_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:17:38.705308Z",
     "iopub.status.busy": "2025-03-29T15:17:38.704940Z",
     "iopub.status.idle": "2025-03-29T15:18:06.223568Z",
     "shell.execute_reply": "2025-03-29T15:18:06.222507Z",
     "shell.execute_reply.started": "2025-03-29T15:17:38.705276Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -r /kaggle/working/arcade-nl2code/arcade_nl2code/evaluation/requirements.txt\n",
    "!pip install -r /kaggle/working/arcade-nl2code/requirements_2022.txt\n",
    "!pip install seqio\n",
    "!pip install diff_match_patch  # was missing in requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip show tensorflow\n",
    "pip show tensorflow-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download ARCADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T15:18:13.027352Z",
     "iopub.status.busy": "2025-03-29T15:18:13.027080Z"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d googleai/arcade-nl2code-dataset -p arcade_nl2code/annotated_dataset/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/arcade_nl2code/annotated_dataset/dataset\n",
    "!unzip -o arcade-nl2code-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /kaggle/working/arcade_nl2code/annotated_dataset\n",
    "PYTHONPATH=../../ \n",
    "python /kaggle/working/arcade-nl2code/arcade_nl2code/annotated_dataset/build_existing_tasks_split.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --force-reinstall pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def execute_intent_code(exec_state, code):\n",
    "    \"\"\"\n",
    "    Executes the given code in the provided execution state.\n",
    "    Returns the updated execution state and any outputs, capturing only primitive types, tuples, \n",
    "    and DataFrames (DataFrames are stored in JSON format).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use a non-interactive backend for matplotlib to suppress plots\n",
    "        plt.switch_backend('Agg')\n",
    "        \n",
    "        # Execute the code in the provided execution state\n",
    "        exec(code, exec_state)\n",
    "        \n",
    "        # Clear any matplotlib figures created during execution\n",
    "        plt.close('all')\n",
    "        \n",
    "        # Capture the outputs (all variables in the execution state)\n",
    "        outputs = {}\n",
    "        for key, value in exec_state.items():\n",
    "            if not key.startswith(\"__\"):\n",
    "                if isinstance(value, (int, float, str, bool, tuple)):\n",
    "                    outputs[key] = value\n",
    "                elif isinstance(value, pd.DataFrame):\n",
    "                    # Convert DataFrame to JSON format\n",
    "                    outputs[key] = value.to_json(orient=\"records\")\n",
    "    except Exception as e:\n",
    "        outputs = {\"error\": str(e)}\n",
    "    \n",
    "    return outputs, exec_state\n",
    "\n",
    "def transform_dataset(datasets_json, n_rows=10, top_n_entries=None):\n",
    "    \"\"\"\n",
    "    Transforms the ARCADE dataset to the desired format by reading the initial input\n",
    "    and executing each intent one by one, processing only the top `top_n_entries` entries.\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(datasets_json, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Limit to the top `top_n_entries` if specified\n",
    "    if top_n_entries is not None:\n",
    "        data = data[:top_n_entries]\n",
    "    \n",
    "    # Number of rows to extract\n",
    "    N = n_rows\n",
    "    \n",
    "    ARTIFACT_PATH = '/kaggle/working/arcade_nl2code/annotated_dataset/dataset/existing_tasks/artifacts'\n",
    "    \n",
    "    # Extract intent, code pairs, and first N rows of the dataset, and execute each intent\n",
    "    rows = []\n",
    "    for entry in tqdm(data):\n",
    "        nb_name = entry.get(\"notebook_name\")\n",
    "        work_dir = entry.get(\"work_dir\")\n",
    "        \n",
    "        # Construct the dataset folder path\n",
    "        dataset_folder_path = os.path.join(ARTIFACT_PATH, work_dir)\n",
    "        \n",
    "        # Find all CSV files in the folder\n",
    "        csv_files = glob(os.path.join(dataset_folder_path, \"*.csv\"))\n",
    "        \n",
    "        # Load the first CSV file if any exist\n",
    "        if csv_files:\n",
    "            dataset_file_path = csv_files[0]  # Use the first CSV file\n",
    "    \n",
    "            # Detect the file encoding\n",
    "            with open(dataset_file_path, \"rb\") as f:\n",
    "                result = chardet.detect(f.read())\n",
    "                encoding = result[\"encoding\"]\n",
    "    \n",
    "            # Use the detected encoding\n",
    "            dataset_df = pd.read_csv(dataset_file_path, encoding=encoding)\n",
    "            first_n_rows = pd.DataFrame(dataset_df.head(N))  # Convert to DataFrame\n",
    "        else:\n",
    "            first_n_rows = None  # Handle missing dataset files\n",
    "       \n",
    "        # First turn input are the imports and dataset load, so execute it first\n",
    "        nb_header = entry.get(\"turns\", [])[0][\"input\"]\n",
    "\n",
    "        # Replace CSV reads with the first_n_rows DataFrame\n",
    "        if first_n_rows is not None:\n",
    "            dataset_file_name = os.path.basename(dataset_file_path)\n",
    "            nb_header = nb_header.replace(\n",
    "                f\"pd.read_csv('{dataset_file_name}')\", \"first_n_rows\"\n",
    "            ).replace(\n",
    "                f'pd.read_csv(\"{dataset_file_name}\")', \"first_n_rows\")\n",
    "\n",
    "        exec_state = {\"pd\": pd, \"first_n_rows\": first_n_rows}  # Add first_n_rows to exec_state\n",
    "        outputs, exec_state = execute_intent_code(exec_state, nb_header)\n",
    "        \n",
    "        # Initialize the execution state with the output from the header execution\n",
    "        inputs = outputs \n",
    "\n",
    "        # Serialize the exec_state using pickle\n",
    "        serialized_exec_state = pickle.dumps(exec_state)\n",
    "        \n",
    "        for i, turn in enumerate(entry.get(\"turns\", [])):\n",
    "            intent = turn[\"turn\"][\"intent\"][\"value\"]\n",
    "            code = turn[\"turn\"][\"code\"][\"value\"]\n",
    "            \n",
    "            # Execute the code intent\n",
    "            outputs, exec_state = execute_intent_code(exec_state, code)\n",
    "            \n",
    "            # Append the results\n",
    "            rows.append({\n",
    "                \"nb_name\": nb_name,\n",
    "                \"work_dir\": work_dir,\n",
    "                'nb_setup_code': nb_header,\n",
    "                \"intent_number\": i,\n",
    "                \"intent\": intent,\n",
    "                \"code\": code,\n",
    "                \"exec_state\": str(serialized_exec_state),\n",
    "                \"inputs\": inputs,  # Inputs for this intent\n",
    "                \"outputs\": outputs,  # Outputs from this intent\n",
    "            })\n",
    "\n",
    "            # Update inputs for the next intent\n",
    "            inputs = outputs\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = transform_dataset(\n",
    "    '/kaggle/working/arcade_nl2code/annotated_dataset/dataset/existing_tasks/dataset.json',\n",
    "    n_rows=10,\n",
    "    top_n_entries=None  # limit num notebooks to process\n",
    ")\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"arcade_existing_transformed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /kaggle/working/arcade_nl2code/annotated_dataset\n",
    "PYTHONPATH=../../  \n",
    "python /kaggle/working/arcade-nl2code/arcade_nl2code/annotated_dataset/build_new_tasks_split.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install faketime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "DATASET_ROOT=/kaggle/working/arcade_nl2code/annotated_dataset/dataset\n",
    "MAX_PROMPT_SIZE=900\n",
    "faketime \"2022-12-10 12:00:00\" python -m arcade_nl2code.annotated_dataset.generate_schema_augmented_prompts \\\n",
    "    --dataset ${DATASET_ROOT}/existing_tasks/dataset.json \\\n",
    "    --output_folder ${DATASET_ROOT}/existing_tasks/derived_datasets/ \\\n",
    "    --runtime_artifacts_root ${DATASET_ROOT}/existing_tasks/artifacts/ \\\n",
    "    --schema_representation_method \"originating_dfs.header_description.after_variable_cell\" \\\n",
    "    --max_prompt_size ${MAX_PROMPT_SIZE} \\\n",
    "    --truncate_metadata_path ${DATASET_ROOT}/existing_tasks/derived_datasets/dataset.schema.originating_dfs.header_description.after_variable_cell.maxp900.maxp_no_prefix-1.maxctxcell-1.truncate_metadata.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "PYTHONPATH=. python /kaggle/working/arcade-nl2code/arcade_nl2code/evaluation/scripts/get_dummy_prediction.py \\\n",
    "    --input /kaggle/working/arcade_nl2code/annotated_dataset/dataset/new_tasks/derived_datasets/dataset.+schema.originating_dfs.header_description.after_variable_cell.maxp900.maxp_no_prefix-1.maxctxcell-1.json \\\n",
    "    --output /kaggle/working/arcade_nl2code/evaluation/test_data/dummy_prediction.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y docker.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!service docker start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /kaggle/working/arcade-nl2code/arcade_nl2code/evaluation/\n",
    "\n",
    "docker build -t notebook_evaluator .\n",
    "\n",
    "PROJECT_ROOT=\"$(dirname `pwd`)\"\n",
    "docker run -it --shm-size=2g \\\n",
    "  --mount type=bind,source=${PROJECT_ROOT}/evaluation/test_data/,target=/data \\\n",
    "  --mount type=bind,source=${PROJECT_ROOT}/annotated_dataset/dataset/new_tasks/artifacts,target=/artifacts \\\n",
    "  -w / \\\n",
    "  --entrypoint /opt/conda/bin/python \\\n",
    "  notebook_evaluator:latest \\\n",
    "  -m arcade_nl2code.evaluation.execution_evaluation_main \\\n",
    "  --prediction_file /data/dummy_prediction.json \\\n",
    "  --output_path /data/ \\\n",
    "  --runtime_artifact_root /artifacts \\\n",
    "  --lm_output_postprocessor extract_first_cell_block  \\\n",
    "  --split_episode \\\n",
    "  --noreuse_state \\\n",
    "  --timeout 30 \\\n",
    "  --num_workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
