{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openai import AsyncOpenAI\n",
    "from anthropic import AsyncAnthropic\n",
    "import anthropic\n",
    "import openai\n",
    "import asyncio\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "semaphore = asyncio.Semaphore(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CSVS_BASE_PATH=\"Spider2/spider2-lite/resource/databases/csv_dbs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCADE_COLUMNS = [\"nb_name\",\"work_dir\",\"nb_header\",\"intent_number\",\"intent\",\"code\",\"inputs\",\"outputs\"]\n",
    "OPEN_AI_40_MINI = \"4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "anthropic_client = AsyncAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "# gemini_model = genai.GenerativeModel(model_name=model or \"gemini-2.0-flash-thinking-exp-01-21\",)\n",
    "# gemini_client = genai.GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_METADATAS_PATH=\"Spider2/spider2-lite/resource/databases/sqlite/\"\n",
    "#You need to download the sqlite dbs manually and unzip them here\n",
    "DATABASES_PATH=\"Spider2/spider2-lite/resource/databases/spider2-localdb/\" \n",
    "DB_CSVS_BASE_PATH=\"Spider2/spider2-lite/resource/databases/csv_dbs\"\n",
    "EVALUATION_SET_PATH=\"Spider2/spider2-lite/spider2-lite.jsonl\"\n",
    "SPIDER2_LOCAL_DB_LINK = \"https://drive.usercontent.google.com/download?id=1coEVsCZq-Xvj9p2TnhBFoFTsY-UoYGmG&export=download&authuser=0&confirm=t&uuid=e4894821-9b03-4a4a-b574-9e931c7f6497&at=AEz70l4CupjM1wWNkGFVtYAST2Xs%3A1743423729461\"\n",
    "GOLD_RESULT_PATH = \"Spider2/spider2-lite/evaluation_suite/gold/exec_result\"\n",
    "\n",
    "def get_table_metadata(database_name, table_name):\n",
    "    table_metadata_file = os.path.join(DB_METADATAS_PATH, database_name, f\"{table_name}.json\")\n",
    "    try:\n",
    "        with open(table_metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "           table_metadata = json.load(f)\n",
    "           return table_metadata\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def get_table_dtype_map(database_name, table_name, sql=False):\n",
    "    table_metadata = get_table_metadata(database_name, table_name)\n",
    "    dtype_map = dict(\n",
    "        zip(\n",
    "            table_metadata.get(\"column_names\", []),\n",
    "            table_metadata.get(\"column_types\", []),\n",
    "        )\n",
    "    )\n",
    "    if sql:\n",
    "        return dtype_map\n",
    "    else:\n",
    "        try:\n",
    "            with open(\"spider_dtype_mappings.json\", \"r\") as f:\n",
    "                mappings = json.load(f)\n",
    "                dtype_map = {k: mappings.get(v.lower(), \"object\") for k, v in dtype_map.items()}\n",
    "                return dtype_map\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "def load_csv_database(database_name, rows_limit=10, as_dict=False):\n",
    "    \"\"\"\n",
    "    Load a CSV-dumped database into a dictionary where each key is a table name and the value is a pandas DataFrame.\n",
    "\n",
    "    :param database_path: Path to the directory containing the CSV files representing the database.\n",
    "    :return: A dictionary with table names as keys and pandas DataFrames as values.\n",
    "    \"\"\"\n",
    "    path1 = os.path.join(DB_CSVS_BASE_PATH, database_name)\n",
    "    path2 = path1.replace(\"-\", \"_\")\n",
    "    path3 = path1.replace(\"_\", \"-\")\n",
    "    path = [x for x in [path1, path2, path3] if os.path.exists(x)]\n",
    "    if path:\n",
    "        database_path = path[0]\n",
    "    else:\n",
    "        print(\"Failed to get database\")\n",
    "        return None\n",
    "    tables = {}\n",
    "    for file_name in os.listdir(database_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            table_name = os.path.splitext(file_name)[0]\n",
    "            file_path = os.path.join(database_path, file_name)\n",
    "            dtypes = get_table_dtype_map(database_name, table_name)\n",
    "            tables[table_name] = pd.read_csv(file_path,)# dtype=dtypes\n",
    "            if rows_limit >= 0:\n",
    "                tables[table_name] = tables[table_name].iloc[:rows_limit]\n",
    "            if as_dict:\n",
    "                tables[table_name] = tables[table_name].to_dict(orient='records')\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_llm(provider, prompt=\"\", model=None, temperature=0.0, max_tokens=512, messages=None):\n",
    "    try:\n",
    "        messages = messages or [{\"role\": \"user\", \"content\": prompt}]\n",
    "        if provider.lower() == \"openai\":\n",
    "            client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "            response = await client.chat.completions.create(\n",
    "                    model=model or \"gpt-4o-mini\",\n",
    "                    store=False,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens\n",
    "                )\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "        elif provider.lower() == \"anthropic\":\n",
    "            response = await anthropic_client.messages.create(\n",
    "                model=model or \"claude-3-5-haiku-20241022\",\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "            )\n",
    "            return response.content[0].text\n",
    "\n",
    "        elif provider.lower() == \"google\":\n",
    "            gemini_model = genai.GenerativeModel(\n",
    "                model_name=model or \"gemini-2.0-flash-thinking-exp-01-21\",\n",
    "                generation_config={\n",
    "                    \"temperature\": temperature,\n",
    "                    \"top_p\": 0.95,\n",
    "                    \"top_k\": 40,\n",
    "                    \"max_output_tokens\": max_tokens,\n",
    "                    \"response_mime_type\": \"text/plain\",\n",
    "                }\n",
    "            )\n",
    "            response = await gemini_model.generate_content_async(prompt)\n",
    "            # time.sleep(6)\n",
    "            return response.text\n",
    "\n",
    "        else:\n",
    "            return \"Unknown provider.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def call_llm(provider, prompt=\"\", model=None, temperature=0.0, max_tokens=512):\n",
    "#     try:\n",
    "#         if provider.lower() == \"openai\":\n",
    "#             client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "#             response = await client.chat.completions.create(\n",
    "#                     model=model or \"gpt-4o-mini\",\n",
    "#                     store=False,\n",
    "#                     messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#                     temperature=temperature,\n",
    "#                     max_tokens=max_tokens\n",
    "#                 )\n",
    "#             return response.choices[0].message.content\n",
    "\n",
    "#         elif provider.lower() == \"anthropic\":\n",
    "#             response = await anthropic_client.messages.create(\n",
    "#                 model=model or \"claude-3-5-haiku-20241022\",\n",
    "#                 messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "#                 temperature=temperature,\n",
    "#                 max_tokens=max_tokens,\n",
    "#             )\n",
    "#             return response.content[0].text\n",
    "\n",
    "#         elif provider.lower() == \"google\":\n",
    "#             gemini_model = genai.GenerativeModel(\n",
    "#                 model_name=model or \"gemini-2.0-flash-thinking-exp-01-21\",\n",
    "#                 generation_config={\n",
    "#                     \"temperature\": temperature,\n",
    "#                     \"top_p\": 0.95,\n",
    "#                     \"top_k\": 40,\n",
    "#                     \"max_output_tokens\": max_tokens,\n",
    "#                     \"response_mime_type\": \"text/plain\",\n",
    "#                 }\n",
    "#             )\n",
    "#             response = await gemini_model.generate_content_async(prompt)\n",
    "#             # time.sleep(6)\n",
    "#             return response.text\n",
    "\n",
    "#         else:\n",
    "#             return \"Unknown provider.\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_description(input_dict, input_dtypes, db_name=\"\"):\n",
    "    \"\"\"\n",
    "    Generates a description of the database structure, including tables, columns, and their data types.\n",
    "    \"\"\"\n",
    "    description = f\"The following is a list of tables in the {db_name} database, along with a list of the columns in the table, along with their types, where available, in parentheses.\\n\\n\"\n",
    "    \n",
    "    for table_name, sample_rows in input_dict.items():\n",
    "        description += f\"Table: {table_name}\\nColumns: \"\n",
    "        if table_name in input_dtypes:\n",
    "            for column_name, dtype in input_dtypes[table_name].items():\n",
    "                description += f\"{column_name} ({dtype}), \"\n",
    "        else:\n",
    "            description += \"    No column information available.\\n\"\n",
    "        description += \"\\n\\n\"\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_header(db_name, work_dir=\"\"):\n",
    "    header = f\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "{db_name} = dict()\n",
    "for table, table_data in load_csv_database('{db_name}', rows_limit=-1).items():\n",
    "    {db_name}[table] = pd.DataFrame(table_data)\n",
    "OUTPUT_DIR = f\"{work_dir}/output.csv\"\n",
    "\"\"\"\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_description(intent, task):\n",
    "    prompt_steps =  f\"Generate a numbered list of steps, in plain text, easily implementable with pandas and python to accomplish the following task. Your final step should be to write the resulting data to a csv file to the path specified in `OUTPUT_DIR`. Do not generate any code at this time\"\n",
    "    prompt_single_shot = \"Generate python code that uses the pandas library to accomplish the following task:\"\n",
    "    prompt_gen_from_steps = f\"Generate python code for each of the pregenerated steps you will be provided with to fulfill the following user intent:\"\n",
    "\n",
    "    prompt_task = \"\"\n",
    "    task = task.lower()\n",
    "    if task == \"gen_steps\":\n",
    "        prompt_task = prompt_steps\n",
    "    elif task == \"gen_single_shot\":\n",
    "        prompt_task = prompt_single_shot\n",
    "    elif task == \"gen_from_steps\":\n",
    "        prompt_task = prompt_gen_from_steps\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "{prompt_task}\n",
    "{intent}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = get_task_description(\"make me an omelette\", \"gen_single_shot\")\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_generated_steps(llm_response):\n",
    "    \"\"\"\n",
    "    Parses a string response from an LLM into a list of steps using regex.\n",
    "\n",
    "    Args:\n",
    "        llm_response (str): The LLM-generated response containing a numbered list of steps.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of steps as strings.\n",
    "    \"\"\"\n",
    "    # Use regex to match lines starting with a number followed by a period and a space\n",
    "    step_pattern = re.compile(r'^\\d+\\.{0,1}\\s+(.*)', flags=re.MULTILINE)\n",
    "    steps = step_pattern.findall(llm_response)\n",
    "    return steps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_generated_steps(\"\"\"1. step 1\\n2. step 2\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_prompt(db_name, input_dict, output_dict, input_dtypes, intent, task, work_dir=\"\"):\n",
    "    header = make_header(db_name, work_dir)\n",
    "    task_description = get_task_description(intent, task)\n",
    "    db_description = get_db_description(input_dict=input_dict, input_dtypes=input_dtypes)\n",
    "    \n",
    "    full_prompt = f\"\"\"\n",
    "{db_description}\n",
    "{task_description}\n",
    "\n",
    "The following code has been pre-written. As such, you do not need to handle loading the data:\n",
    "{header}\n",
    "Be concise. Generate only valid Python code. Don’t include any other explanations other than Python comments. Don't make any assumptons about currently existing code\n",
    "\"\"\"\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "# def make_multi_turn_prompt(db_name, input_dict, output_dict, input_dtypes, intent, task):\n",
    "#     header = make_header(db_name)\n",
    "#     task_description = get_task_description(intent, task)\n",
    "#     db_description = get_db_description(input_dict=input_dict, input_dtypes=input_dtypes)    \n",
    "\n",
    "#     multi_prompt = f\"\"\"The following is your task: {task_description}.\n",
    "\n",
    "# A sequence of steps to achieve this task has been pre-generated. Your role is to execute each step using Python to accomplish the task. The subsequent messages will provide individual steps toward the goal, which you must implement.\n",
    "\n",
    "# {db_description}\n",
    "\n",
    "# The following code has been pre-written. As such, you do not need to handle loading the data:\n",
    "# {header}    \n",
    "# \"\"\"\n",
    "#     return multi_prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_prompt_from_df_row(df_row, task):\n",
    "    db_name = df_row[\"db_name\"]\n",
    "    input_dict = df_row[\"inputs\"]\n",
    "    output_dict = df_row[\"outputs\"]\n",
    "    input_dtypes = df_row[\"d_types\"]\n",
    "    intent = df_row[\"intent\"]\n",
    "    work_dir  = f\"output/{task}/{df_row['work_dir']}\"\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    if task in (\"gen_single_shot\", \"gen_steps\", \"gen_from_steps\"):\n",
    "        return make_full_prompt(db_name=db_name,\n",
    "                                input_dict=input_dict,\n",
    "                                output_dict=output_dict,\n",
    "                                input_dtypes=input_dtypes,\n",
    "                                intent=intent,\n",
    "                                task=task,\n",
    "                                work_dir=work_dir)\n",
    "    return \"\"\n",
    "    # elif task in (\"gen_from_steps\"):\n",
    "    #     return make_multi_turn_prompt(db_name=db_name,\n",
    "    #                             input_dict=input_dict,\n",
    "    #                             output_dict=output_dict,\n",
    "    #                             input_dtypes=input_dtypes,\n",
    "    #                             intent=intent,\n",
    "    #                             task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_spider = pd.DataFrame(pd.read_pickle(\"datasets/llm_etl_spider2_df.pickle\"))\n",
    "llm_etl_spider = llm_etl_spider[llm_etl_spider[\"d_types\"] != {}]\n",
    "# llm_etl_spider =  llm_etl_spider.sample(15)\n",
    "# llm_etl_spider = llm_etl_spider.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = make_full_prompt_from_df_row(llm_etl_spider.iloc[0], task=\"gen_from_steps\")\n",
    "\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = {\n",
    "    \"gpt-4o-mini\": (\"openai\", \"gpt-4o-mini\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_task_row(df_row, task, provider, model, temperature=0.0, max_tokens=512):\n",
    "    prompt = make_full_prompt_from_df_row(df_row=df_row, task=task)\n",
    "    response = \"\"\n",
    "    response = await call_llm(\n",
    "            provider=provider, \n",
    "            prompt=prompt, \n",
    "            model=model, \n",
    "            temperature=temperature, \n",
    "            max_tokens=max_tokens\n",
    "            )\n",
    "    return response\n",
    "\n",
    "\n",
    "async def process_dataframe_rows(df:pd.DataFrame, task, provider, model, column_name=None, in_place=True):\n",
    "    \"\"\"\n",
    "    Processes the rows of a dataframe asynchronously.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing rows to process.\n",
    "        task (str): The task to perform.\n",
    "        provider (str): The provider to use (e.g., \"openai\").\n",
    "        engine (str): The engine to use (e.g., \"4o-mini\").\n",
    "\n",
    "    Returns:\n",
    "        list: A list of responses for each row.\n",
    "    \"\"\"\n",
    "    task_df = df if in_place else df.copy()\n",
    "\n",
    "    tasks = [\n",
    "        run_task_row(df_row=row, task=task, provider=provider, model=model)\n",
    "        for _, row in task_df.iterrows()\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    column_name = column_name or f\"{task}_{provider}_{model}\"\n",
    "    \n",
    "    # Use pandas' assign method for better practice\n",
    "    task_df = task_df.assign(**{column_name: results})\n",
    "    \n",
    "    return task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = llm_etl_spider.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_spider_filtered = llm_etl_spider[llm_etl_spider[\"d_types\"] != {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = make_full_prompt_from_df_row(df_row=llm_etl_spider.iloc[0], task=\"gen_single_shot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_spider_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arcade_like_dataset(df, save_file_name=None):\n",
    "    # arcade_like_df = pd.DataFrame(columns=ARCADE_COLUMNS)\n",
    "    arcade_df_rows = []\n",
    "    curr_intent_id = 0\n",
    "    notebook_dict = defaultdict(int)\n",
    "    for idx, row in df.iterrows(): \n",
    "        steps = parse_generated_steps(row['gen_steps'])\n",
    "        db_name = row[\"db_name\"]\n",
    "        work_dir = f\"dataset_{db_name}/notebook_{notebook_dict[db_name]}\"\n",
    "        nb_name = f\"dataset_{db_name}/notebook_{notebook_dict[db_name]}/annotated.ipynb\"\n",
    "        notebook_dict[db_name] += 1\n",
    "        \n",
    "        for step in steps:\n",
    "            arcade_df_rows.append({\n",
    "                    \"nb_name\": nb_name,\n",
    "                    \"work_dir\": work_dir,\n",
    "                    \"nb_header\": make_header(db_name, work_dir),\n",
    "                    \"intent_number\": curr_intent_id,\n",
    "                    \"intent\": step,\n",
    "                    \"code\": row[\"code\"],\n",
    "                    \"inputs\": row[\"inputs\"],\n",
    "                    \"outputs\": row[\"outputs\"],\n",
    "                    \"db_name\": row[\"db_name\"],\n",
    "                    \"d_types\": row[\"d_types\"],\n",
    "                    \"spider_task_id\": row[\"work_dir\"]\n",
    "                }\n",
    "            )\n",
    "            curr_intent_id += 1\n",
    "    arcade_like_df = pd.DataFrame(arcade_df_rows)\n",
    "    if save_file_name:\n",
    "        arcade_like_df.to_pickle(f\"{save_file_name}.pickle\")\n",
    "    return arcade_like_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = build_arcade_like_dataset(df, save_file_name=\"gemini.steps.spider2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "for provider in [\"openai\"]:#, \"anthropic\", \"google\"]: #\"openai\", \"google\",\n",
    "    #Just to be safe, load the input df everytime\n",
    "    this_df = pd.DataFrame(pd.read_pickle(\"datasets/llm_etl_spider2_df.pickle\"))\n",
    "    this_df = this_df.iloc[:15]\n",
    "    #filter out the bad rows\n",
    "    this_df = this_df[this_df[\"d_types\"] != {}]\n",
    "    for task in [\"gen_steps\", \"gen_single_shot\"]:\n",
    "        this_df = await process_dataframe_rows(this_df, task=task, provider=provider, model=model, column_name=task, in_place=True)\n",
    "    this_df.to_pickle(f\"datasets/{provider}.single_shot.spider2.pickle\")\n",
    "    arcade_df = build_arcade_like_dataset(this_df)\n",
    "    arcade_df.to_pickle(f\"datasets/{provider}.arcade.spider2.pickle\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_steps_oai = pd.read_pickle(f\"datasets/openai.arcade.spider2.pickle\")\n",
    "# sample = llm_etl_steps_oai.iloc[:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_etl_steps_oai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code_markers(code_string):\n",
    "    \"\"\"\n",
    "    Removes ```python and ``` markers from a code string.\n",
    "    \n",
    "    Args:\n",
    "        code_string (str): The input string containing code with markers\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned code without the markers\n",
    "    \"\"\"\n",
    "    # Remove ```python at the start (with optional whitespace)\n",
    "    cleaned = code_string.replace('```python', '').strip()\n",
    "    \n",
    "    # Remove ``` at the end (with optional whitespace)\n",
    "    cleaned = cleaned.replace('```', '').strip()\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_intent_code(exec_state, code, verbose=False):\n",
    "    # print(code)\n",
    "    \"\"\"\n",
    "    Executes the given code in the provided execution state.\n",
    "    Returns the updated execution state and any outputs, capturing only primitive types, tuples, \n",
    "    and DataFrames (DataFrames are stored in JSON format).\n",
    "\n",
    "    exec_state: python exec namespace\n",
    "\n",
    "    examples:\n",
    "\n",
    "        for executing notebook header:\n",
    "        \n",
    "            first_n_rows = pd.DataFrame(eval(eval(intents.iloc[0][INPUT_DATA_COL].replace('null', 'None'))['first_n_rows']))\n",
    "            exec_state = {\"pd\": pd, \"first_n_rows\": first_n_rows}  # Initialize execution state\n",
    "            try:\n",
    "                outputs, exec_state = execute_intent_code(exec_state, nb_header, verbose=False)\n",
    "                inputs = outputs  # Initialize inputs with the header execution outputs\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing notebook header for {nb_name}: {e}\")\n",
    "                continue  # Skip this notebook if the header fails\n",
    "\n",
    "        for executing intent code (note exec_state would have been previously modified from previous intent code execution)\n",
    "            # Execute original code\n",
    "            try:\n",
    "                print(\"Executing original code...\")\n",
    "                original_outputs, exec_state = execute_intent_code(exec_state, actual_code, verbose=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing original code: {e}\")\n",
    "                original_outputs = {}\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use a non-interactive backend for matplotlib to suppress plots\n",
    "        plt.switch_backend('Agg')\n",
    "\n",
    "        if verbose:\n",
    "            print(\"IN STATE\")\n",
    "            print(exec_state)\n",
    "            print(\"CODE\")\n",
    "            print(code)\n",
    "\n",
    "        # Execute the code in the provided execution state\n",
    "        exec(code, exec_state)\n",
    "\n",
    "        # Clear any matplotlib figures created during execution\n",
    "        plt.close('all')\n",
    "        \n",
    "        # Capture the outputs (all variables in the execution state)\n",
    "        outputs = {}\n",
    "        for key, value in exec_state.items():\n",
    "            if not key.startswith(\"__\"):\n",
    "                if isinstance(value, (int, float, str, bool, tuple)):\n",
    "                    outputs[key] = value\n",
    "                elif isinstance(value, pd.DataFrame):\n",
    "                    # Convert DataFrame to JSON format\n",
    "                    # outputs[key] = value\n",
    "                    outputs[f\"#{key}\"] = str(value.iloc[:4].to_json(orient=\"records\"))\n",
    "\n",
    "                elif isinstance(value, pd.Series):\n",
    "                    # Convert Series to JSON format\n",
    "                    # outputs[key] = value\n",
    "                    outputs[f\"*{key}\"] = str(value.iloc[:4].to_json())\n",
    "\n",
    "        if verbose:\n",
    "            print(\"OUT STATE\")\n",
    "            print(exec_state)\n",
    "            print(\"OUTPUTS\")\n",
    "            print(outputs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(code)\n",
    "        print(\"Error in executing code: \", e)\n",
    "        outputs = {\"_error\": str(e)}\n",
    "    \n",
    "    return outputs, exec_state\n",
    "\n",
    "\n",
    "def build_output_description_str(output_dict):\n",
    "    \"\"\"\n",
    "    Builds a string description of the outputs from the execution state.\n",
    "\n",
    "    Args:\n",
    "        output_dict (dict): A dictionary containing the outputs from the execution state.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string describing the outputs.\n",
    "    \"\"\"\n",
    "    description = \"The following variables are in the namespace following the previous step:\\n\"\n",
    "    for key, value in output_dict.items():\n",
    "        if key.startswith(\"#\"):\n",
    "            description += f\"- DataFrame '{key[1:]}' (sample): {value}\\n\"\n",
    "        elif key.startswith(\"*\"):\n",
    "            description += f\"- Series '{key[1:]}' (sample): {value}\\n\"\n",
    "        elif key == \"_error\":\n",
    "            description += f\"- Error: {value}\\n\"\n",
    "        else:\n",
    "            description += f\"- {key}: {value}\\n\"\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_multiturn_code_gen(\n",
    "    provider,\n",
    "    model,\n",
    "    system_prompt: str,\n",
    "    header: str, \n",
    "    steps: list,\n",
    "    temperature=0.7,\n",
    "    include_output=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates a multi-turn conversation with an LLM.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt (str): Initial system prompt to set the behavior of the assistant.\n",
    "        user_turns (list): A list of user messages to simulate the dialogue.\n",
    "        model (str): The LLM model name.\n",
    "        temperature (float): Sampling temperature.\n",
    "    Returns:\n",
    "        list: A list of assistant responses.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    responses = []\n",
    "\n",
    "    exec_state = {\"pd\": pd, \"load_csv_database\": load_csv_database}\n",
    "    output, exec_state = execute_intent_code(exec_state, header)\n",
    "    \n",
    "    if \"_error\" in output:\n",
    "        responses.extend([\"exec_error\"] * (len(steps) - len(responses)))\n",
    "        return responses\n",
    "    \n",
    "    output_str = build_output_description_str(output)\n",
    "\n",
    "    for step in steps:\n",
    "        user_m = step if not include_output else f\"{output_str}\\n{step}\"\n",
    "        messages.append({\"role\": \"user\", \"content\": user_m})\n",
    "        time.sleep(9)\n",
    "        response = await call_llm(\n",
    "            provider=provider,\n",
    "            model=model,\n",
    "            temperature=0,\n",
    "            max_tokens=512,\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        assistant_reply = clean_code_markers(response)\n",
    "        output, exec_state = execute_intent_code(exec_state, assistant_reply)\n",
    "        output_str = build_output_description_str(output)\n",
    "        if \"_error\" in output:\n",
    "            responses.extend([\"exec_error\"] * (len(steps) - len(responses)))\n",
    "            return responses\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "        responses.append(assistant_reply)\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_and_merge_groups_async(df, groupby_columns, new_column_name, process_function):\n",
    "    \"\"\"\n",
    "    Asynchronously disaggregates the rows of a dataframe via a groupby, processes each group by adding a new column,\n",
    "    and merges the groups back together.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe.\n",
    "        groupby_columns (list): List of columns to group by.\n",
    "        new_column_name (str): Name of the new column to add to each group.\n",
    "        process_function (callable): An async function that takes a group dataframe and returns a series or list\n",
    "                                     to be added as the new column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed dataframe with the new column added.\n",
    "    \"\"\"\n",
    "    print(df.columns)\n",
    "    grouped = df.groupby(groupby_columns)\n",
    "    processed_groups = []\n",
    "\n",
    "    async def process_group(group):\n",
    "        group[new_column_name] = await process_function(group)\n",
    "        return group\n",
    "\n",
    "    tasks = [process_group(group) for _, group in grouped]\n",
    "    processed_groups = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Concatenate all processed groups back into a single dataframe\n",
    "    result_df = pd.concat(processed_groups, ignore_index=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_steps_multiturn_no_fb(df):\n",
    "    \"\"\"\n",
    "    Processes the steps in a DataFrame for multi-turn code generation without feedback.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing steps and other metadata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with an additional column for generated code.\n",
    "    \"\"\"\n",
    "    header = df.iloc[0][\"nb_header\"]\n",
    "    header = make_header(df.iloc[0][\"db_name\"], f\"output/gen_from_steps/{df.iloc[0][\"work_dir\"]}\")\n",
    "    steps = df[\"intent\"]\n",
    "    system_prompt = make_full_prompt_from_df_row(df.iloc[0], task=\"gen_from_steps\")\n",
    "    generated_code = await run_multiturn_code_gen(\n",
    "        provider=\"openai\",\n",
    "        model=None,\n",
    "        system_prompt=system_prompt,\n",
    "        header=header,\n",
    "        steps=steps,\n",
    "        include_output=True,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return generated_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df = await process_and_merge_groups_async(sample, groupby_columns=\"nb_name\", new_column_name=\"gen_step_code\", process_function=process_steps_multiturn_no_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = llm_etl_steps_oai\n",
    "async with semaphore:\n",
    "    processed_df = await process_and_merge_groups_async(\n",
    "        sample, \n",
    "        groupby_columns=\"nb_name\", \n",
    "        new_column_name=\"gen_step_code\", \n",
    "        process_function=process_steps_multiturn_no_fb\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df.iloc[6][\"gen_step_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = llm_etl_steps_oai.drop_duplicates(subset=[\"work_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "target_folder = \"gen_exec_results\"\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for _, gg_row in gg.iterrows():\n",
    "    # Construct the source file path\n",
    "    source_path = f\"output/gen_from_steps/output/{gg_row['work_dir']}/output.csv\"\n",
    "    \n",
    "    # Construct the destination file path\n",
    "    destination_path = os.path.join(target_folder, f\"{gg_row['spider_task_id']}.csv\")\n",
    "    \n",
    "    # Copy the file if it exists\n",
    "    if os.path.exists(source_path):\n",
    "        shutil.copy(source_path, destination_path)\n",
    "    else:\n",
    "        # Create an empty file with the appropriate name\n",
    "        with open(destination_path, 'w') as f:\n",
    "            f.write(\"output,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
