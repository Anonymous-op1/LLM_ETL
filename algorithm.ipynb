{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face1172",
   "metadata": {
    "_cell_guid": "719e61df-fa4f-4afe-b84b-77ea6800b91a",
    "_uuid": "30b1c62a-abaf-4117-903a-25a45f9489c3",
    "execution": {
     "iopub.execute_input": "2025-05-25T22:32:40.792532Z",
     "iopub.status.busy": "2025-05-25T22:32:40.792023Z",
     "iopub.status.idle": "2025-05-25T22:33:12.170227Z",
     "shell.execute_reply": "2025-05-25T22:33:12.169234Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 31.386775,
     "end_time": "2025-05-25T22:33:12.172226",
     "exception": false,
     "start_time": "2025-05-25T22:32:40.785451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import model_eval as me\n",
    "import spider_utils_py as sp_utils\n",
    "from spider_utils_py import load_csv_database\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63677458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.186274Z",
     "iopub.status.busy": "2025-05-25T22:33:12.185657Z",
     "iopub.status.idle": "2025-05-25T22:33:12.190802Z",
     "shell.execute_reply": "2025-05-25T22:33:12.189890Z"
    },
    "papermill": {
     "duration": 0.013744,
     "end_time": "2025-05-25T22:33:12.192633",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.178889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# M\n",
    "GLOBAL_ROUND_COUNT = 1\n",
    "# N\n",
    "GLOBAL_ITERATION_COUNT = 1\n",
    "# Number of notebooks to predict\n",
    "GLOBAL_RUN_ALL = True\n",
    "\n",
    "GLOBAL_NOTEBOOK_COUNT = 1\n",
    "if GLOBAL_RUN_ALL:\n",
    "    GLOBAL_NOTEBOOK_COUNT = 'ALL'\n",
    "# Number of Intents to trim\n",
    "GLOBAL_MAX_CHAR_LIMIT = 500000 #512000\n",
    "# Number of lines of returned outputs\n",
    "GLOBAL_CODE_OUTPUT_LINES = 10\n",
    "# LLM Model Selection\n",
    "GLOBAL_LLM_MODEL = 'anthropic'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e4b16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.207043Z",
     "iopub.status.busy": "2025-05-25T22:33:12.206672Z",
     "iopub.status.idle": "2025-05-25T22:33:12.295519Z",
     "shell.execute_reply": "2025-05-25T22:33:12.294513Z"
    },
    "papermill": {
     "duration": 0.098551,
     "end_time": "2025-05-25T22:33:12.297366",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.198815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Load the Arcade dataset\n",
    "# df =  me.load_from_pkl('arcade_dataset_path')\n",
    "# df['generated_intent_code'] = None\n",
    "# df['generated_output'] = None\n",
    "# df['original_index'] = df.index  # Add a column to store the original index\n",
    "\n",
    "\n",
    "# # Load the Spider-2 Lite dataset\n",
    "df_spider2 = pd.read_pickle(\"spider_two_intents_path\")\n",
    "df_spider2['generated_intent_code'] = None\n",
    "df_spider2['generated_output'] = None\n",
    "df_spider2['original_index'] = df_spider2.index  # Add a column to store the original index\n",
    "df_spider2 = df_spider2[df_spider2['execute_error'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027ed44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.310932Z",
     "iopub.status.busy": "2025-05-25T22:33:12.310503Z",
     "iopub.status.idle": "2025-05-25T22:33:12.315619Z",
     "shell.execute_reply": "2025-05-25T22:33:12.314168Z"
    },
    "papermill": {
     "duration": 0.014145,
     "end_time": "2025-05-25T22:33:12.317631",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.303486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for loading spider2 database\n",
    "load_csv_database = sp_utils.load_csv_database\n",
    "CSV_DBS_BASE_PATH =  \"/kaggle/input/spider-dbs-csv\"\n",
    "os.environ[\"DB_CSVS_BASE_PATH\"] = CSV_DBS_BASE_PATH #The spider_util needs this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7fba4",
   "metadata": {
    "_cell_guid": "719e61df-fa4f-4afe-b84b-77ea6800b91a",
    "_uuid": "30b1c62a-abaf-4117-903a-25a45f9489c3",
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.330719Z",
     "iopub.status.busy": "2025-05-25T22:33:12.330375Z",
     "iopub.status.idle": "2025-05-25T22:33:12.335534Z",
     "shell.execute_reply": "2025-05-25T22:33:12.334550Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.0137,
     "end_time": "2025-05-25T22:33:12.337314",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.323614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_code_from_llm(prompt):\n",
    "    \"\"\"\n",
    "    Generate Python code using the Google Gemini LLM via the call_llm function.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt: String containing the task description and context\n",
    "    \n",
    "    Returns:\n",
    "    - String of generated Python code\n",
    "    \"\"\"\n",
    "    generated_code = me.call_llm(\n",
    "        provider=GLOBAL_LLM_MODEL,\n",
    "        prompt=prompt,  # Use the evolved_prompt from build_prompt\n",
    "        temperature=0,\n",
    "        max_tokens=8192\n",
    "    )\n",
    "    return generated_code\n",
    "\n",
    "# Global context for all prompts\n",
    "global_context = \"\"\"\n",
    "You are a skilled data engineer tasked with completing existing Python code for the next user intent.  \n",
    "You are provided the previous code, sample rows of the data frames available after executing the previous code, \n",
    "and next user intent to implement. Code generated in previous iterations will be provided. Think step by step.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31931002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.350278Z",
     "iopub.status.busy": "2025-05-25T22:33:12.349896Z",
     "iopub.status.idle": "2025-05-25T22:33:12.358356Z",
     "shell.execute_reply": "2025-05-25T22:33:12.357109Z"
    },
    "papermill": {
     "duration": 0.017139,
     "end_time": "2025-05-25T22:33:12.360328",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.343189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(global_context, old_rounds, current_round_blocks, base_prompt, current_index=None, current_round_num=None):\n",
    "    \"\"\"\n",
    "    Build the evolved prompt with labeled previous code and outputs, trimming history to stay below a character limit.\n",
    "    Parameters:\n",
    "    - old_rounds: List of previous rounds' blocks\n",
    "    - current_round_blocks: List of blocks from the current round so far\n",
    "    - current_index: Index of the current intent (optional, for labeling)\n",
    "    - current_round_num: Current round number (optional, for labeling)\n",
    "    \"\"\"\n",
    "    prompt_string = global_context\n",
    "    prompt_string += \"\\n\"\n",
    "    # 1) Add the base prompt with existing code\n",
    "    prompt_string += base_prompt\n",
    "    \n",
    "    # 2) Collect all intents into a flat list\n",
    "    all_intents = []\n",
    "    for round_idx, round_blocks in enumerate(old_rounds, start=1):\n",
    "        for block_idx, block in enumerate(round_blocks):\n",
    "            all_intents.append((round_idx, block_idx, block))\n",
    "    if current_round_blocks:\n",
    "        for block_idx, block in enumerate(current_round_blocks):\n",
    "            all_intents.append((current_round_num, block_idx, block))\n",
    "    \n",
    "    # 3) Build history and trim using FIFO strategy based on character limit\n",
    "    history_string = \"# History of generated code and intents from previous iterations \\n\"\n",
    "    trimmed_intents = []\n",
    "    current_char_count = len(history_string)\n",
    "    \n",
    "    # Add intents in reverse order (most recent first) to calculate character count\n",
    "    for intent in reversed(all_intents):\n",
    "        round_idx, block_idx, block = intent\n",
    "        intent_block = f\"\\n\\n# Round {round_idx} Intent {block_idx}\\n\"\n",
    "        intent_block += f\"Intent: {block['intent']}\\n\"\n",
    "        if 'iteration_history' in block and block['iteration_history']:\n",
    "            for iter_idx, iter_block in enumerate(block['iteration_history'], start=1):\n",
    "                intent_block += f\"# Round {round_idx} Iteration {iter_idx}\\n\"\n",
    "                intent_block += f\"Code: {iter_block['code']}\\n\"\n",
    "                intent_block += f\"Output: {iter_block.get('output', 'N/A')}\\n\"\n",
    "        intent_block += f\"Final Code: {block['code']}\\n\"\n",
    "        intent_block += f\"Output: {block.get('output', 'N/A')}\\n\"\n",
    "    \n",
    "        # Check if adding this intent block exceeds the character limit\n",
    "        if current_char_count + len(intent_block) <= GLOBAL_MAX_CHAR_LIMIT:\n",
    "            trimmed_intents.append(intent_block)\n",
    "            current_char_count += len(intent_block)\n",
    "        else:\n",
    "            # Stop adding more intents if the limit is exceeded\n",
    "            break\n",
    "    \n",
    "    # Reverse the trimmed intents to maintain chronological order (oldest to newest)\n",
    "    history_string += \"\".join(reversed(trimmed_intents))\n",
    "    prompt_string += f\"\\n\\n{history_string}\"\n",
    "\n",
    "    prompt_string += \"\\n\\nOutput: \\n\"\n",
    "    prompt_string += \"Generate only valid Python code for the next intent only not the entire notebook. Don't include any other explanations other than Python comments. Don't convert output to json.\"\n",
    "\n",
    "    return prompt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a813b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.373724Z",
     "iopub.status.busy": "2025-05-25T22:33:12.373344Z",
     "iopub.status.idle": "2025-05-25T22:33:12.380081Z",
     "shell.execute_reply": "2025-05-25T22:33:12.379042Z"
    },
    "papermill": {
     "duration": 0.015313,
     "end_time": "2025-05-25T22:33:12.381721",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.366408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterative_llm_prompt(prompt, exec_state, n=None):\n",
    "    \"\"\"\n",
    "    Iteratively call the LLM and re-prompt it n times, passing each generated code\n",
    "    and its execution output back into the prompt for the next iteration.\n",
    "\n",
    "    Returns:\n",
    "      final_code   : The last generated code snippet\n",
    "      final_output : The last execution output\n",
    "      exec_state   : The updated execution state after the final iteration\n",
    "    \"\"\"\n",
    "    current_prompt = prompt\n",
    "    current_state = exec_state.copy()\n",
    "    full_history = []\n",
    "    final_code = None\n",
    "    final_output = None\n",
    "    if n is None:\n",
    "        n = GLOBAL_ITERATION_COUNT\n",
    "\n",
    "    import re\n",
    "    round_match = re.search(r\"Round (\\d+)\", current_prompt)\n",
    "    round_num = int(round_match.group(1)) if round_match else 1\n",
    "\n",
    "    for i in range(n):\n",
    "        print(f\"\\n--- Iteration {i+1}/{n} ---\")\n",
    "        raw_code = generate_code_from_llm(current_prompt)\n",
    "        cleaned_code = me.clean_code_markers(raw_code)\n",
    "        # For the generated code\n",
    "        iteration_output, _ = me.execute_intent_code(current_state, cleaned_code, GLOBAL_CODE_OUTPUT_LINES)\n",
    "        print(f\"Iteration {i+1} - Generated code:\\n{cleaned_code}\\n\")\n",
    "        print(f\"Iteration {i+1} - Execution output:\\n{iteration_output}\\n\")\n",
    "        full_history.append({\n",
    "            \"code\": cleaned_code,\n",
    "            \"output\": iteration_output\n",
    "        })\n",
    "        current_prompt += (\n",
    "            f\"\\n\\n# Round {round_num} Iteration {i+1}\\n\"\n",
    "            f\"Code: {cleaned_code}\\n\"\n",
    "            f\"Output: {iteration_output}\\n\"\n",
    "        )\n",
    "        final_code = cleaned_code\n",
    "        final_output = iteration_output\n",
    "\n",
    "    return final_code, final_output, full_history, current_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5bf30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.395324Z",
     "iopub.status.busy": "2025-05-25T22:33:12.394919Z",
     "iopub.status.idle": "2025-05-25T22:33:12.406977Z",
     "shell.execute_reply": "2025-05-25T22:33:12.405730Z"
    },
    "papermill": {
     "duration": 0.020937,
     "end_time": "2025-05-25T22:33:12.408626",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.387689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_notebooks(df, max_rounds=None):\n",
    "    memory = {}\n",
    "    success_rate = 0\n",
    "    notebooks = df.groupby('nb_name', sort=False)\n",
    "    notebook_count = 0\n",
    "    if max_rounds is None:\n",
    "        max_rounds = GLOBAL_ROUND_COUNT\n",
    "    for round_num in range(1, max_rounds + 1):\n",
    "        print(f\"\\nStarting round {round_num}\\n{'='*20}\")\n",
    "        notebook_count = 0\n",
    "        for nb_name, nb_group in notebooks:\n",
    "            if not GLOBAL_RUN_ALL and notebook_count >= GLOBAL_NOTEBOOK_COUNT:\n",
    "                print(f\"Processed {GLOBAL_NOTEBOOK_COUNT} notebooks in round {round_num}. Moving to next round.\")\n",
    "                break\n",
    "            if nb_name not in memory:\n",
    "                memory[nb_name] = []\n",
    "            new_round_memory = []\n",
    "            round_generated_output = \"\"\n",
    "\n",
    "            print(f\"\\nProcessing notebook: {nb_name}\\n{'-'*20}\")\n",
    "            nb_source = nb_group['nb_setup_code'].iloc[0]\n",
    "            \n",
    "            input_json = nb_group['inputs'].iloc[0]\n",
    "            \n",
    "            exec_state = {\"pd\": pd , \"plt\": plt, \"np\": np, \"load_csv_database\": load_csv_database}\n",
    "            outputs = \"\"   \n",
    "            try:\n",
    "                if isinstance(input_json, str):\n",
    "                    input_dict = ast.literal_eval(input_json)\n",
    "                elif isinstance(input_json, dict):\n",
    "                    input_dict = input_json\n",
    "                else:\n",
    "                    input_dict = {}\n",
    "                    \n",
    "                outputs, exec_state = me.execute_intent_code(exec_state, nb_source)\n",
    "                print(outputs)\n",
    "                # If 'first_n_rows' is missing, proceed with minimal exec_state\n",
    "            except (ValueError, json.JSONDecodeError, SyntaxError):\n",
    "                pass  # Continue with minimal exec_state if parsing fails\n",
    "            # Process all rows in this notebook group\n",
    "            for _, row in nb_group.iterrows():\n",
    "                index = row['original_index']\n",
    "                user_intent = row['intent']\n",
    "                base_prompt = f\"Setup Code: {nb_source}\\n\\n\"\n",
    "                \n",
    "                evolved_prompt = build_prompt(\n",
    "                    global_context,\n",
    "                    memory[nb_name],\n",
    "                    new_round_memory,\n",
    "                    base_prompt,\n",
    "                    nb_name,\n",
    "                    current_round_num=round_num\n",
    "                )\n",
    "\n",
    "                evolved_prompt += f\"Next Intent to implement: {user_intent}\\n\\nSample Input: {outputs}\"\n",
    "                \n",
    "    \n",
    "                print(f\"\\nEvolved Prompt for intent '{user_intent}' (index {index}):\\n{'*'*20}\\n{evolved_prompt}\\n{'*'*20}\")\n",
    "    \n",
    "                generated_code, generated_output, iteration_history, exec_state = iterative_llm_prompt(evolved_prompt, exec_state)\n",
    "                print(f\"Generated code for index {index}: {generated_code}\")\n",
    "    \n",
    "                if generated_code is None:\n",
    "                    print(f\"Warning: Generated code is None for intent '{user_intent}' at index {index}\")\n",
    "                                \n",
    "                print(\"Executing intent code based on generated code\")\n",
    "                print(f\"Generated output for index {index}: {generated_output}\")\n",
    "                \n",
    "                new_round_memory.append({\n",
    "                    \"intent\": user_intent,\n",
    "                    \"code\": generated_code,\n",
    "                    \"output\": generated_output,\n",
    "                    \"iteration_history\": iteration_history\n",
    "                })\n",
    "                \n",
    "                if generated_code is None:\n",
    "                    print(\"No generated code available\")\n",
    "                else:\n",
    "                    df.loc[index, 'generated_intent_code'] = generated_code\n",
    "                if generated_output is None:\n",
    "                    print(\"No generated output available\")\n",
    "                else:\n",
    "                    df.loc[index, 'generated_output'] = str(generated_output)\n",
    "                df.loc[index, 'evolved_prompt'] = evolved_prompt\n",
    "            memory[nb_name].append(new_round_memory)\n",
    "            print(f\"Finished processing all intents for notebook: {nb_name}\")\n",
    "            notebook_count += 1\n",
    "       \n",
    "    print(\"Finished processing all notebooks\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182d701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.421704Z",
     "iopub.status.busy": "2025-05-25T22:33:12.421371Z",
     "iopub.status.idle": "2025-05-25T22:33:12.428421Z",
     "shell.execute_reply": "2025-05-25T22:33:12.427434Z"
    },
    "papermill": {
     "duration": 0.01528,
     "end_time": "2025-05-25T22:33:12.429982",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.414702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def divide_and_process_part(\n",
    "    df: pd.DataFrame,\n",
    "    part: str = \"first\",                # \"first\", \"second\", or \"third\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    part = part.lower()\n",
    "    if part not in {\"first\", \"second\", \"third\"}:\n",
    "        raise ValueError('`part` must be \"first\", \"second\", or \"third\".')\n",
    "\n",
    "    # 1️⃣  Unique task IDs in the order they appear\n",
    "    unique_ids = df[\"spider_task_id\"].drop_duplicates().tolist()\n",
    "    total_ids  = len(unique_ids)\n",
    "    print(f\"Size:f{total_ids}\")\n",
    "    if total_ids == 0:\n",
    "        raise ValueError(\"DataFrame has no rows or no `spider_task_id` values.\")\n",
    "\n",
    "    # 2️⃣  Determine slice bounds\n",
    "    chunk = math.ceil(total_ids / 3)\n",
    "    bounds = {\n",
    "        \"first\" : (0, chunk),\n",
    "        \"second\": (chunk, 2 * chunk),\n",
    "        \"third\" : (2 * chunk, total_ids),\n",
    "    }\n",
    "    start, stop = bounds[part]\n",
    "\n",
    "    # 3️⃣  Select IDs for the chosen slice and subset the DataFrame\n",
    "    id_slice = unique_ids[start:stop]\n",
    "    df_slice = df[df[\"spider_task_id\"].isin(id_slice)].copy()\n",
    "    df_slice = df_slice[df_slice[\"spider_task_id\"] != \"local210\"]\n",
    "    # 4️⃣  Run your existing notebook processor on just this slice\n",
    "    processed_slice = process_notebooks(df_slice)\n",
    "\n",
    "    # 5️⃣  Save to the required location\n",
    "    out_path = (\n",
    "        f\"/kaggle/working/\"\n",
    "        f\"spider2_intents_transformed_generated_\"\n",
    "        f\"{GLOBAL_LLM_MODEL}_{part}_notebooks_m_\"\n",
    "        f\"{GLOBAL_ROUND_COUNT}_n_{GLOBAL_ITERATION_COUNT}.csv\"\n",
    "    )\n",
    "    processed_slice.to_csv(out_path, index=False)\n",
    "    return processed_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fc3db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.443019Z",
     "iopub.status.busy": "2025-05-25T22:33:12.442644Z",
     "iopub.status.idle": "2025-05-25T22:33:12.446412Z",
     "shell.execute_reply": "2025-05-25T22:33:12.445513Z"
    },
    "papermill": {
     "duration": 0.011871,
     "end_time": "2025-05-25T22:33:12.448017",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.436146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Process the Arcade notebooks and update the DataFrame\n",
    "# updated_df = process_notebooks(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7e61a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.460773Z",
     "iopub.status.busy": "2025-05-25T22:33:12.460357Z",
     "iopub.status.idle": "2025-05-25T22:33:12.464286Z",
     "shell.execute_reply": "2025-05-25T22:33:12.463274Z"
    },
    "papermill": {
     "duration": 0.01212,
     "end_time": "2025-05-25T22:33:12.466007",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.453887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the updated DataFrame to a new CSV file\n",
    "# updated_df.to_csv(f'/kaggle/working/arcade_20_new_transformed_generated_{GLOBAL_LLM_MODEL}_{GLOBAL_NOTEBOOK_COUNT}_notebooks_m_{GLOBAL_ROUND_COUNT}_n_{GLOBAL_ITERATION_COUNT}.csv', index=False)\n",
    "# print(f\"Processing complete. Results saved to 'arcade_20_new_transformed_generated_{GLOBAL_LLM_MODEL}_{GLOBAL_NOTEBOOK_COUNT}_notebooks_m_{GLOBAL_ROUND_COUNT}_n_{GLOBAL_ITERATION_COUNT}.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3827d54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T22:33:12.478594Z",
     "iopub.status.busy": "2025-05-25T22:33:12.478250Z",
     "iopub.status.idle": "2025-05-25T22:33:12.482146Z",
     "shell.execute_reply": "2025-05-25T22:33:12.481015Z"
    },
    "papermill": {
     "duration": 0.012185,
     "end_time": "2025-05-25T22:33:12.483914",
     "exception": false,
     "start_time": "2025-05-25T22:33:12.471729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Process the Spider2 notebooks and update the DataFrame and Save to CSV file\n",
    "# updated_df_spider2 = process_notebooks(df_spider2)\n",
    "# updated_df_spider2.to_csv(f'/kaggle/working/spider2_transformed_generated_{GLOBAL_LLM_MODEL}_one_notebooks_m_{GLOBAL_ROUND_COUNT}_n_{GLOBAL_ITERATION_COUNT}.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7101196,
     "sourceId": 11349944,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7116834,
     "sourceId": 11369318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7078100,
     "sourceId": 11884618,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7035263,
     "sourceId": 11890043,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 229490371,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 233954297,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 240880404,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.80264,
   "end_time": "2025-05-25T22:33:13.711139",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T22:32:37.908499",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
